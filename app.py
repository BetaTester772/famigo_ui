import cv2
import mediapipe as mp
from facenet_pytorch import InceptionResnetV1
from PIL import Image
import torchvision.transforms as transforms
import os
from enum import Enum
import torch
import numpy as np
import sounddevice as sd
from collections import deque
import time
import soundfile as sf
import threading

# ====== ì „ì—­ í”Œë˜ê·¸ ì¶”ê°€ ======
VAD_TASK_STARTED = False
VAD_TASK_RUNNING = False

ASR_TASK_STARTED = False
ASR_TASK_RUNNING = False
ASR_TEXT = None

import ssl

ssl._create_default_https_context = ssl._create_unverified_context


# =========================
# VAD Recorder
# =========================

class VADRecorder:
    def __init__(self):
        # Load model
        self.model, self.utils = torch.hub.load(
                repo_or_dir='snakers4/silero-vad',
                model='silero_vad',
                # force_reload=True,
                trust_repo=True
        )
        self.vad_iterator = self.utils[3](self.model)  # VADIterator is the 4th element

        # Settings
        self.SAMPLE_RATE = 16000
        self.BUFFER_SIZE = self.SAMPLE_RATE * 60  # 1 minute buffer
        self.THRESHOLD = 0.65
        self.MIN_DURATION = 0.5
        self.MARGIN = 1
        self.SILENCE_TIME = 0.6

        # State
        self.reset_state()

    def reset_state(self):
        self.audio_buffer = deque(maxlen=self.BUFFER_SIZE)
        self.is_speaking = False
        self.speech_start_sample = None
        self.sample_counter = 0
        self.silence_counter = 0
        self.ema_speech_prob = 0
        self.saved_filename = None

    def _save_audio_segment(self, start_sample, end_sample):
        audio_array = np.array(list(self.audio_buffer), dtype=np.int16)
        start = max(0, start_sample - int(self.MARGIN * self.SAMPLE_RATE))
        end = min(len(audio_array), end_sample + int(self.MARGIN * self.SAMPLE_RATE))
        segment = audio_array[start:end]

        if len(segment) / self.SAMPLE_RATE < self.MIN_DURATION:
            print(f"Segment too short, skipping save.")
            return

        filename = f"speech_{time.strftime('%Y%m%d_%H%M%S')}.wav"
        sf.write(filename, segment, self.SAMPLE_RATE)
        print(f"Audio saved: {filename}")
        self.saved_filename = filename

    def _callback(self, indata, frames, time_info, status):
        if status:
            print(status)

        if self.saved_filename:  # Stop if we already have a file
            return

        audio_int16 = (indata * 32768).astype(np.int16).flatten()
        self.audio_buffer.extend(audio_int16)

        if len(audio_int16) < 512:
            return

        audio_tensor = torch.from_numpy(audio_int16).float()
        speech_prob = self.vad_iterator.model(audio_tensor, self.SAMPLE_RATE).item()
        self.ema_speech_prob = 0.9 * self.ema_speech_prob + 0.1 * speech_prob

        if self.ema_speech_prob > self.THRESHOLD:
            if not self.is_speaking:
                self.is_speaking = True
                self.speech_start_sample = self.sample_counter
            self.silence_counter = 0
        else:
            if self.is_speaking:
                self.silence_counter += frames / self.SAMPLE_RATE
                if self.silence_counter >= self.SILENCE_TIME:
                    self.is_speaking = False
                    speech_end_sample = self.sample_counter
                    duration = (speech_end_sample - self.speech_start_sample) / self.SAMPLE_RATE
                    if duration >= self.MIN_DURATION:
                        self._save_audio_segment(self.speech_start_sample, speech_end_sample)

        self.sample_counter += frames

    def record(self, timeout=10):
        self.reset_state()
        stream = sd.InputStream(callback=self._callback, channels=1, samplerate=self.SAMPLE_RATE, blocksize=512)
        with stream:
            print("Listening for speech...")
            start_time = time.time()
            while time.time() - start_time < timeout:
                if self.saved_filename:
                    break
                sd.sleep(100)

        print("Finished listening.")
        return self.saved_filename


# For use in other scripts
def listen_and_record_speech(timeout=10):
    """
    Creates a VADRecorder instance and records one speech segment.
    Returns the filename or None.
    """
    recorder = VADRecorder()
    filename = recorder.record(timeout=timeout)
    return filename


# =========================
# State Definition
# =========================

class State(Enum):
    IDLE = 0
    USER_CHECK = 1
    ENROLL = 2
    WELCOME = 3
    ASR = 4
    BYE = 5


# =========================
# Globals & Flags
# =========================

FACE_DETECTED = False
USER_EXIST = False
ENROLL_SUCCESS = False
VAD = False
BYE_EXIST = False
TIMER_EXPIRED = False  # WELCOME, BYE state's timer

# Shared between states
sh_face_crop = None
sh_bbox = None
sh_embedding = None
sh_current_user = None
sh_audio_file = None
sh_message = "Initializing..."
sh_color = (255, 255, 0)
sh_timer_end = 0
sh_prev_unkonw = None

# =========================
# Utils
# =========================

DB_PATH = "faces_db.npy"
SIM_THRESHOLD = 0.65


def load_db():
    if os.path.exists(DB_PATH):
        data = np.load(DB_PATH, allow_pickle=True).item()
        return data["name_list"], data["group_list"], data["embeddings"]
    else:
        return [], [], np.empty((0, 512))


def save_db(name_list, group_list, embeddings):
    np.save(DB_PATH, {"name_list": name_list, "group_list": group_list, "embeddings": embeddings})


def find_match(embedding, name_list, embeddings):
    if len(embeddings) == 0:
        return None, 0
    sims = [np.dot(embedding, emb) / (np.linalg.norm(embedding) * np.linalg.norm(emb)) for emb in embeddings]
    max_idx = np.argmax(sims)
    if sims[max_idx] >= SIM_THRESHOLD:
        return name_list[max_idx], sims[max_idx]
    else:
        return None, sims[max_idx]


# Face detection & bbox
def update_face_detection():
    global FACE_DETECTED, sh_face_crop, sh_bbox, sh_frame

    image = sh_frame.copy()
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = face_detection.process(rgb_image)

    if results.detections and len(results.detections) == 1:
        FACE_DETECTED = True
        detection = results.detections[0]
        bboxC = detection.location_data.relative_bounding_box
        ih, iw, _ = image.shape
        x, y, w, h = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)
        x, y = max(0, x), max(0, y)
        sh_bbox = (x, y, w, h)
        sh_face_crop = image[y:y + h, x:x + w]
        if sh_face_crop.size == 0:
            FACE_DETECTED = False
    else:
        FACE_DETECTED = False
        sh_bbox = None
        sh_face_crop = None

    return results


# =========================
# ASR (Whisper)
# =========================

import whisper

whisper_model = whisper.load_model("large-v3")


def asr_from_wav(file_path: str) -> str:
    print(f"./{file_path}",
          os.path.exists(f"./{file_path}"))
    result = whisper_model.transcribe(f"./{file_path}")
    print(result)
    return result['text']


# =========================
# State Action Functions
# =========================

def enter_idle():
    global sh_message, sh_color
    results = update_face_detection()
    if not FACE_DETECTED:
        if results.detections and len(results.detections) > 1:
            sh_message = f"{len(results.detections)} faces detected. Only one please."
            sh_color = (0, 0, 255)
        else:
            sh_message = "Waiting for user..."
            sh_color = (255, 255, 0)


def enter_user_check():
    global USER_EXIST, sh_embedding, sh_current_user, sh_message, sh_color

    update_face_detection()
    if sh_face_crop is None:
        return

    face_pil = Image.fromarray(cv2.cvtColor(sh_face_crop, cv2.COLOR_BGR2RGB))
    face_tensor = preprocess(face_pil).unsqueeze(0)
    with torch.no_grad():
        embedding = resnet(face_tensor)[0].cpu().numpy()
    sh_embedding = embedding / np.linalg.norm(embedding)

    match_name, sim = find_match(sh_embedding, name_list, embeddings)
    if match_name:
        USER_EXIST = True
        sh_current_user = match_name
        sh_message = f"Identifying... {match_name} ({sim:.2f})"
        sh_color = (0, 255, 0)
    else:
        USER_EXIST = False
        sh_message = "Unknown user. Use the right panel to enroll."
        sh_color = (0, 255, 255)


def enter_enroll(key=None):
    # key kept for compatibility; do not reset ENROLL_SUCCESS here!
    global sh_message, sh_color

    results = update_face_detection()

    if not FACE_DETECTED:
        if results.detections and len(results.detections) > 1:
            sh_message = f"{len(results.detections)} faces detected. Only one please."
            sh_color = (0, 0, 255)
        else:
            sh_message = "ë“±ë¡ì„ ìœ„í•´ ì–¼êµ´ì„ ì¹´ë©”ë¼ì— ë¹„ì¶°ì£¼ì„¸ìš”."
            sh_color = (255, 255, 0)
    else:
        sh_message = "ì•Œ ìˆ˜ ì—†ëŠ” ì‚¬ìš©ìì…ë‹ˆë‹¤. ì˜¤ë¥¸ìª½ íŒ¨ë„ì˜ í¼ìœ¼ë¡œ ë“±ë¡í•˜ì„¸ìš”."
        sh_color = (0, 255, 255)


def enter_welcome():
    global VAD, sh_audio_file, TIMER_EXPIRED, sh_message, sh_color

    update_face_detection()

    # ë©”ì‹œì§€/ìƒ‰ìƒ
    sh_message = f"Hi, {sh_current_user}!"
    sh_color = (0, 255, 0)

    # íƒ€ì´ë¨¸ ë§Œë£Œ ì—¬ë¶€ë¥¼ ë§¤ í”„ë ˆì„ ê³„ì‚°
    TIMER_EXPIRED = (time.time() > sh_timer_end)

    # íƒ€ì´ë¨¸ê°€ ëë‚¬ê³ , ì•„ì§ ë…¹ìŒ ì‹œì‘ ì•ˆ í–ˆìœ¼ë©´ ë¹„ë™ê¸° ì‹œì‘
    if TIMER_EXPIRED and not VAD_TASK_STARTED:
        start_vad_async(timeout=5)


def enter_asr():
    update_face_detection()

    # ì˜¤ë””ì˜¤ê°€ ìˆê³ , ì•„ì§ ASR ì‹œì‘ ì•ˆ í–ˆìœ¼ë©´ ë¹„ë™ê¸° ì‹œì‘
    if sh_audio_file and not ASR_TASK_STARTED:
        start_asr_async(sh_audio_file)


def enter_bye():
    global TIMER_EXPIRED, sh_message, sh_color

    update_face_detection()

    TIMER_EXPIRED = False
    sh_message = f"Bye, {sh_current_user}!"
    sh_color = (255, 0, 255)

    if time.time() > sh_timer_end:
        TIMER_EXPIRED = True


def start_vad_async(timeout=5):
    """ë…¹ìŒì„ ë¹„ë™ê¸°ë¡œ ì‹œì‘í•œë‹¤. ì™„ë£Œ ì‹œ sh_audio_file, VAD ê°±ì‹ ."""
    global VAD_TASK_STARTED, VAD_TASK_RUNNING
    if VAD_TASK_RUNNING:  # ì´ë¯¸ ì‹¤í–‰ ì¤‘
        return
    VAD_TASK_STARTED = True
    VAD_TASK_RUNNING = True

    def _worker():
        global sh_audio_file, VAD, VAD_TASK_RUNNING
        try:
            filename = listen_and_record_speech(timeout=timeout)
            if filename:
                sh_audio_file = filename
                VAD = True
            else:
                VAD = False
        finally:
            VAD_TASK_RUNNING = False

    threading.Thread(target=_worker, daemon=True).start()


def start_asr_async(file_path: str):
    """Whisperë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰í•œë‹¤. ì™„ë£Œ ì‹œ ASR_TEXT, BYE_EXIST ê°±ì‹ ."""
    global ASR_TASK_STARTED, ASR_TASK_RUNNING
    if ASR_TASK_RUNNING:
        return
    ASR_TASK_STARTED = True
    ASR_TASK_RUNNING = True

    def _worker():
        global ASR_TEXT, BYE_EXIST, ASR_TASK_RUNNING
        try:
            text = asr_from_wav(file_path)
            ASR_TEXT = text
            t = "".join(text.split())
            BYE_EXIST = ("ì˜ê°€" in t) or ("bye" in t.lower())
        finally:
            ASR_TASK_RUNNING = False

    threading.Thread(target=_worker, daemon=True).start()


# =========================
# Transitions & Dispatcher
# =========================

def state_transition(current_state: State) -> State:
    global sh_prev_unkonw, sh_embedding, name_list, group_list, embeddings

    if current_state == State.IDLE:
        return State.USER_CHECK if FACE_DETECTED else State.IDLE

    elif current_state == State.USER_CHECK:
        return State.WELCOME if USER_EXIST else State.ENROLL

    elif current_state == State.ENROLL:
        if ENROLL_SUCCESS:
            name_list, group_list, embeddings = load_db()
            return State.WELCOME
        sh_prev_unkonw = sh_embedding
        return State.IDLE if not FACE_DETECTED else State.ENROLL

    elif current_state == State.WELCOME:
        # íƒ€ì´ë¨¸ê°€ ëë‚˜ì§€ ì•Šì•˜ìœ¼ë©´ WELCOME ìœ ì§€
        if not (time.time() > sh_timer_end):
            return State.WELCOME
        # íƒ€ì´ë¨¸ ëë‚¨: ë…¹ìŒì´ ëë‚¬ìœ¼ë©´ ASRë¡œ, ë…¹ìŒ ì§„í–‰ ì¤‘ì´ë©´ WELCOME ìœ ì§€, (ì‹¤íŒ¨/ë¯¸ì‹œì‘)ë©´ IDLE
        if VAD:
            return State.ASR
        if VAD_TASK_RUNNING:
            return State.WELCOME
        # ë…¹ìŒì´ ì•ˆ ì‹œì‘/ì‹¤íŒ¨í•œ ê²½ìš°ì—” ëŒ€ê¸° ì¢…ë£Œ -> IDLE
        return State.IDLE

    elif current_state == State.ASR:
        # ASR ì§„í–‰ ì¤‘ì´ë©´ ASR ìœ ì§€
        if ASR_TASK_RUNNING:
            return State.ASR
        # ASRì´ ëë‚¬ë‹¤ë©´ ê²°ê³¼ì— ë”°ë¼ BYE / IDLE
        if ASR_TASK_STARTED and not ASR_TASK_RUNNING:
            return State.BYE if BYE_EXIST else State.IDLE
        # ì•„ì§ ì‹œì‘ ì¡°ê±´(ì˜¤ë””ì˜¤ ë¯¸ì¡´ì¬ ë“±) ë¯¸ì¶©ì¡± ì‹œ ASR ìœ ì§€
        return State.ASR

    elif current_state == State.BYE:
        return State.IDLE if TIMER_EXPIRED else State.BYE

    return current_state


def call_state_fn(state: State, key):
    if state == State.IDLE:
        enter_idle()
    elif state == State.USER_CHECK:
        enter_user_check()
    elif state == State.ENROLL:
        enter_enroll(key)
    elif state == State.WELCOME:
        enter_welcome()
    elif state == State.ASR:
        enter_asr()
    elif state == State.BYE:
        enter_bye()


# =========================
# Model Init
# =========================

print("Loading models...")
resnet = InceptionResnetV1(pretrained='vggface2').eval()
mp_face_detection = mp.solutions.face_detection
face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)
preprocess = transforms.Compose([
        transforms.Resize((160, 160)), transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])
name_list, group_list, embeddings = load_db()
print("Models loaded.")

# =========================
# Streamlit UI & Main Loop
# =========================

import streamlit as st

st.set_page_config(page_title="Face Kiosk", layout="wide")
st.title("ğŸ‘¤ Face Kiosk with State UI")

# Layout
col_video, col_ui = st.columns([3, 2], vertical_alignment="top")

# Camera / Options
with col_video:
    st.subheader("ğŸ“· Camera")
    cam_index = st.number_input("Camera index", min_value=0, max_value=10, value=0, step=1)
    width = st.slider("Frame width", 320, 1920, 640, step=10)
    run = st.toggle("Run camera", value=False)
    frame_slot = st.empty()

# UI placeholders
with col_ui:
    st.subheader("ğŸ§­ State Panel")
    state_badge = st.empty()
    message_slot = st.empty()
    enroll_slot = st.empty()
    welcome_slot = st.empty()
    asr_slot = st.empty()
    bye_slot = st.empty()
    audio_slot = st.empty()
    debug_slot = st.expander("Debug", expanded=False)

# Keep only camera handle in session_state
if "cap" not in st.session_state:
    st.session_state.cap = None


def open_camera(index: int, target_w: int):
    cap = cv2.VideoCapture(index)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, target_w)
    return cap


# ENROLL UI lifecycle flags & unique keys
ENROLL_UI_BUILT = False
enroll_face_ph = None
enroll_form_counter = 0
current_enroll_form_key = None
current_enroll_name_key = None
current_enroll_group_key = None

# Initial state
state = State.IDLE
st.caption("Starting state machine...")


# ENROLL submit helper
def ui_enroll_submit(new_name: str, new_group: str):
    global ENROLL_SUCCESS, USER_EXIST, name_list, group_list, embeddings, sh_current_user

    if not new_name or new_name.strip() == "":
        st.warning("ì´ë¦„ì€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
        return
    if sh_embedding is None or len(sh_embedding) == 0:
        st.error("ì–¼êµ´ ì„ë² ë”©ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ì— ì–¼êµ´ì„ ë˜‘ë°”ë¡œ ë¹„ì¶°ì£¼ì„¸ìš”.")
        return
    if any(n == new_name for n in name_list):
        st.warning("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì´ë¦„ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.")
        return

    name_list.append(new_name)
    group_list.append(new_group)

    if embeddings.size:
        embeddings = np.vstack([embeddings, sh_embedding])
    else:
        embeddings = np.array([sh_embedding])

    save_db(name_list, group_list, embeddings)

    sh_current_user = new_name
    ENROLL_SUCCESS = True
    USER_EXIST = True

    st.success(f"ë“±ë¡ ì™„ë£Œ: {new_name} ({new_group if new_group else 'group ë¯¸ì§€ì •'})")
    print("[DB Updated] ", name_list, group_list, embeddings.shape)


if run:
    # Open camera once
    if st.session_state.cap is None or not st.session_state.cap.isOpened():
        st.session_state.cap = open_camera(int(cam_index), int(width))
        if not st.session_state.cap.isOpened():
            st.error("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¸ë±ìŠ¤ë¥¼ ë°”ê¾¸ê±°ë‚˜ ë‹¤ë¥¸ ì•±ì„ ì¢…ë£Œí•´ë³´ì„¸ìš”.")
            st.stop()


    # UI helper: render state panel
    def render_state_panel(current_state: State):
        global ENROLL_UI_BUILT, enroll_face_ph
        global current_enroll_form_key, current_enroll_name_key, current_enroll_group_key

        # Badge
        state_badge.markdown(f"**Current State:** :blue[{current_state.name}]")

        # ENROLL ì™¸ ìƒíƒœ ìŠ¬ë¡¯ ì •ë¦¬
        if current_state != State.ENROLL:
            enroll_slot.empty()
        if current_state != State.WELCOME:
            welcome_slot.empty()
        if current_state != State.ASR:
            asr_slot.empty()
        if current_state != State.BYE:
            bye_slot.empty()

        # Message
        with message_slot.container():
            st.markdown(f"**Message:** {sh_message}")

        # ENROLL UI (form created once per entry)
        if current_state == State.ENROLL:
            # ì•ˆì „ì¥ì¹˜: í˜¹ì‹œ í‚¤ê°€ Noneì´ë©´ ì¦‰ì„ ìƒì„±
            if current_enroll_form_key is None or current_enroll_name_key is None or current_enroll_group_key is None:
                ts = int(time.time() * 1000)
                current_enroll_form_key = f"form_enroll_{ts}"
                current_enroll_name_key = f"enroll_name_{ts}"
                current_enroll_group_key = f"enroll_group_{ts}"

            if not ENROLL_UI_BUILT:
                ENROLL_UI_BUILT = True
                with enroll_slot.container():
                    st.info("ì•Œ ìˆ˜ ì—†ëŠ” ì‚¬ìš©ìì…ë‹ˆë‹¤. ì•„ë˜ í¼ìœ¼ë¡œ ë“±ë¡ì„ ì§„í–‰í•˜ì„¸ìš”.")
                    enroll_face_ph = st.empty()

                    # ê³ ìœ  í‚¤ ì‚¬ìš©
                    with st.form(key=current_enroll_form_key, clear_on_submit=False):
                        new_name = st.text_input("ì´ë¦„", key=current_enroll_name_key)
                        new_group = st.text_input("ê·¸ë£¹(ì„ íƒ)", key=current_enroll_group_key)
                        submitted = st.form_submit_button("ë“±ë¡í•˜ê¸°", use_container_width=True)
                    if submitted:
                        ui_enroll_submit(new_name, new_group)

            # ì–¼êµ´ ë¯¸ë¦¬ë³´ê¸° ê°±ì‹ 
            if enroll_face_ph is not None:
                if sh_face_crop is not None and sh_face_crop.size != 0:
                    face_rgb = cv2.cvtColor(sh_face_crop, cv2.COLOR_BGR2RGB)
                    enroll_face_ph.image(face_rgb, caption="ë“±ë¡í•  ì–¼êµ´", use_container_width=True)
                else:
                    enroll_face_ph.warning("ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ë¥¼ í–¥í•´ í•œ ëª…ë§Œ ë¹„ì¶°ì£¼ì„¸ìš”.")
        else:
            # Leaving ENROLL -> flag reset (í¼ì€ ìˆ¨ê²¨ì ¸ ìˆì§€ë§Œ ê°™ì€ run ë‚´ ì¬ìƒì„± ë°©ì§€ìš©ìœ¼ë¡œ í‚¤ë¥¼ ë°”ê¿”ì„œ ë‹¤ìŒ ì§„ì… ì‹œ ìƒˆ í¼ ìƒì„±)
            if ENROLL_UI_BUILT:
                ENROLL_UI_BUILT = False
                enroll_face_ph = None

        # WELCOME UI ì¶”ê°€ ë¶€ë¶„ (ë…¹ìŒ ì§„í–‰ì¤‘ í‘œì‹œ)
        if current_state == State.WELCOME:
            with welcome_slot.container():
                if not (time.time() > sh_timer_end):
                    remain = max(0.0, sh_timer_end - time.time())
                    st.success(f"Hi, **{sh_current_user}**! ê³§ ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤.")
                    st.progress(min(max(1.0 - (remain / 2.0), 0.0), 1.0), text="Greeting...")
                else:
                    if VAD_TASK_RUNNING:
                        st.info("ğŸ™ï¸ ìŒì„± ë…¹ìŒ ì¤‘...")
                    elif VAD:
                        st.success("ğŸ§ ìŒì„± ìº¡ì²˜ ì™„ë£Œ! ASRë¡œ ì´ë™í•©ë‹ˆë‹¤.")
                    else:
                        st.warning("ë…¹ìŒì„ ì‹œì‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ëŒì•„ê°‘ë‹ˆë‹¤.")

        # ASR UI ì¶”ê°€ ë¶€ë¶„ (ASR ì§„í–‰ì¤‘ í‘œì‹œ)
        if current_state == State.ASR:
            with asr_slot.container():
                if ASR_TASK_RUNNING:
                    st.info("ğŸ§  Whisperë¡œ ìŒì„±ì„ ë³€í™˜ ì¤‘...")
                elif ASR_TEXT is not None:
                    st.write("**ASR ê²°ê³¼:** ", ASR_TEXT)
                    st.write(f"**BYE detected:** {'Yes' if BYE_EXIST else 'No'}")
                else:
                    st.write("ëŒ€ê¸° ì¤‘...")

        # BYE UI
        if current_state == State.BYE:
            with bye_slot.container():
                st.warning(f"Bye, **{sh_current_user}**!")
                remain = max(0.0, sh_timer_end - time.time())
                pct = min(max(1.0 - (remain / 2.0), 0.0), 1.0)
                st.progress(pct, text="Ending...")


    # Main loop
    while run:
        success, sh_frame = st.session_state.cap.read()
        if not success:
            st.error("í”„ë ˆì„ì„ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            break

        # Key (kept for compatibility; not used for enroll)
        key = cv2.waitKey(1) & 0xFF

        # Call & transition
        previous_state = state
        call_state_fn(state, key)
        new_state = state_transition(state)

        # ë©”ì¸ ë£¨í”„ì—ì„œ ìƒíƒœ ë³€ê²½ ì²˜ë¦¬ ë¶€ë¶„ë§Œ êµì²´/í™•ì¥
        if new_state != state:
            print(f"State Change: {state.name} -> {new_state.name}")

            # ENROLLë¡œ ë“¤ì–´ì˜¬ ë•Œ: ë“±ë¡ ê´€ë ¨ ì´ˆê¸°í™”
            if new_state == State.ENROLL and state != State.ENROLL:
                ENROLL_SUCCESS = False
                USER_EXIST = False
                ENROLL_UI_BUILT = False  # ìƒˆ ENROLL ì„¸ì…˜ì—ì„œ í¼ 1íšŒ ìƒì„±

                # ê³ ìœ  í‚¤ ìƒì„± (ì¤‘ë³µ ë°©ì§€)
                enroll_form_counter += 1
                current_enroll_form_key = f"form_enroll_{enroll_form_counter}"
                current_enroll_name_key = f"enroll_name_{enroll_form_counter}"
                current_enroll_group_key = f"enroll_group_{enroll_form_counter}"

            # WELCOMEë¡œ ë“¤ì–´ì˜¬ ë•Œ: íƒ€ì´ë¨¸/ë…¹ìŒ í”Œë˜ê·¸ ì´ˆê¸°í™”
            if new_state == State.WELCOME:
                sh_timer_end = time.time() + 2.0  # 2ì´ˆ ì¸ì‚¬
                # ë…¹ìŒ ë¹„ë™ê¸° ìƒíƒœ ì´ˆê¸°í™”
                VAD = False
                VAD_TASK_STARTED = False
                VAD_TASK_RUNNING = False
                sh_audio_file = None

            # ASRë¡œ ë“¤ì–´ì˜¬ ë•Œ: ASR ë¹„ë™ê¸° ìƒíƒœ ì´ˆê¸°í™”
            if new_state == State.ASR:
                ASR_TEXT = None
                BYE_EXIST = False
                ASR_TASK_STARTED = False
                ASR_TASK_RUNNING = False

            # BYEë¡œ ë“¤ì–´ì˜¬ ë•Œ: bye íƒ€ì´ë¨¸
            if new_state == State.BYE:
                sh_timer_end = time.time() + 2.0

            state = new_state

        # Update state panel
        render_state_panel(state)

        # Draw overlays
        display_frame = sh_frame.copy()

        if sh_bbox:
            x, y, w, h = sh_bbox
            cv2.rectangle(display_frame, (x, y), (x + w, y + h), sh_color, 2)
            cv2.putText(display_frame, sh_message, (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, sh_color, 2)
        else:
            cv2.putText(display_frame, sh_message, (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, sh_color, 2)

        # Show frame
        frame_rgb = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
        h0, w0, _ = frame_rgb.shape
        new_h = int(h0 * (width / w0))
        frame_rgb = cv2.resize(frame_rgb, (int(width), new_h))
        frame_slot.image(frame_rgb, channels="RGB", caption="Live", use_container_width=True)

        # Debug info
        with debug_slot:
            st.write({
                    "FACE_DETECTED" : FACE_DETECTED,
                    "USER_EXIST"    : USER_EXIST,
                    "ENROLL_SUCCESS": ENROLL_SUCCESS,
                    "VAD"           : VAD,
                    "BYE_EXIST"     : BYE_EXIST,
                    "TIMER_EXPIRED" : TIMER_EXPIRED,
                    "current_user"  : sh_current_user,
                    "audio_file"    : sh_audio_file
            })

        time.sleep(0.01)
        run = st.session_state.get("_toggle_run", True)

    # Cleanup
    if st.session_state.cap is not None:
        st.session_state.cap.release()
        st.session_state.cap = None
        frame_slot.empty()
        st.info("ì¹´ë©”ë¼ë¥¼ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤.")
